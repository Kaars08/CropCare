{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf9bc0b-662c-4bb5-b902-221b96c153aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def total_files(folder_path):\n",
    "    num_files = len(f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)))\n",
    "    return num_files\n",
    "\n",
    "train_files_healthy = \"Dataset/Train/Train/Healthy\"\n",
    "train_files_powdery = \"Dataset/Train/Train/Powdery\"\n",
    "train_files_rust = \"Dataset/Train/Train/Rust\"\n",
    "\n",
    "test_files_healthy = \"Dataset/Test/Test/Healthy\"\n",
    "test_files_powdery = \"Dataset/Test/Test/Powdery\"\n",
    "test_files_rust = \"Dataset/Test/Test/Rust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd49216-6095-42a8-a13f-a67805793efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator as idg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada73c7c-7910-4d8d-85cc-5b5edd5c817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = idg(rescale = 1./255, shear_range = 0.2, zoom_range= 0.2, horizontal_flip = True)\n",
    "test_datagen = idg(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af679705-7225-46a9-86d9-d7509d884d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1322 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\"Dataset/Train/Train\", target_size=(225,225), batch_size=32, class_mode=\"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\"Dataset/Validation/Validation\", target_size=(225, 225), batch_size = 32, class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c48f2e4-9a1c-40d9-ab1f-50f2b4c9525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten , Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape = (225, 225, 3) , activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49052a75-7ebb-48eb-af3c-494363472397",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c603ad0c-2aa5-4ecb-b874-239535a7e765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "42/42 [==============================] - 185s 4s/step - loss: 1.9311 - accuracy: 0.4667 - val_loss: 0.7305 - val_accuracy: 0.5667\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 191s 5s/step - loss: 0.8041 - accuracy: 0.5923 - val_loss: 0.7139 - val_accuracy: 0.6500\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 246s 6s/step - loss: 0.6392 - accuracy: 0.7027 - val_loss: 0.6656 - val_accuracy: 0.6833\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 250s 6s/step - loss: 0.4731 - accuracy: 0.7965 - val_loss: 0.5232 - val_accuracy: 0.7833\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 244s 6s/step - loss: 0.4050 - accuracy: 0.8366 - val_loss: 0.5205 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, batch_size=16, epochs = 5, validation_data=validation_generator, validation_batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c6b80e-144f-49e7-8bcd-912a53a5b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "42/42 [==============================] - 246s 6s/step - loss: 0.3314 - accuracy: 0.8691 - val_loss: 0.5408 - val_accuracy: 0.8500\n",
      "Epoch 2/2\n",
      "42/42 [==============================] - 239s 6s/step - loss: 0.2591 - accuracy: 0.9153 - val_loss: 0.4890 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, batch_size=16, epochs = 2, validation_data=validation_generator, validation_batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f7dc7b-909d-49e7-ba32-169a8c0a0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4966f78-a825-4c7c-a706-68298ad64e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(image_path, target_size = (225, 225)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    x = img_to_array(img)\n",
    "    x = x.astype(\"float32\")/ 255\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    return x\n",
    "\n",
    "x = preprocess(\"Dataset/Test/Test/Rust/82f49a4a7b9585f1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46890967-1f76-46fd-919e-18e7fe1de178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9562123e-02, 4.5072194e-04, 8.9998710e-01], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x)\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfc08be4-fd66-47e6-a7c9-f1331dc6e2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Healthy', 1: 'Powdery', 2: 'Rust'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_generator.class_indices\n",
    "labels = {v: k for k, v in labels.items()}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dff466e-7217-4cc0-8468-1db74554eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rust\n"
     ]
    }
   ],
   "source": [
    "pred = labels[np.argmax(prediction)]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a7e807-2189-4429-80c6-a89e0e69f26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
